{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: {'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 6.1; x64; fr; rv:1.9.2.13) Gecko/20101203 Firebird/3.6.13'}\n"
     ]
    }
   ],
   "source": [
    "import twint\n",
    "import json\n",
    "import pandas as pd\n",
    "from twitterscraper import query_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = twint.Config()\n",
    "c.Username = \"now\"\n",
    "c.Search = \"fruit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "# twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2006-03-21 until:2006-11-24', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2006-11-24 until:2007-07-31', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2007-07-31 until:2008-04-05', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2008-04-05 until:2008-12-10', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2008-12-10 until:2009-08-15', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2009-08-15 until:2010-04-21', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2010-04-21 until:2010-12-26', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2010-12-26 until:2011-09-01', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2011-09-01 until:2012-05-06', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2012-05-06 until:2013-01-10', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2013-01-10 until:2013-09-16', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2013-09-16 until:2014-05-23', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2014-05-23 until:2015-01-26', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2015-01-26 until:2015-10-02', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2015-10-02 until:2016-06-07', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2016-06-07 until:2017-02-11', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2017-02-11 until:2017-10-17', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2017-10-17 until:2018-06-23', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2018-06-23 until:2019-02-27', 'soybeans (from:business) until:2019-11-03 since:2017-11-14 since:2019-02-27 until:2019-11-03']\n",
      "INFO: Got 20 tweets (20 new).\n",
      "INFO: Got 40 tweets (20 new).\n",
      "INFO: Got 60 tweets (20 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: queries: ['farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2006-03-21 until:2006-11-24', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2006-11-24 until:2007-07-31', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2007-07-31 until:2008-04-05', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2008-04-05 until:2008-12-10', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2008-12-10 until:2009-08-15', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2009-08-15 until:2010-04-21', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2010-04-21 until:2010-12-26', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2010-12-26 until:2011-09-01', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2011-09-01 until:2012-05-06', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2012-05-06 until:2013-01-10', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2013-01-10 until:2013-09-16', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2013-09-16 until:2014-05-23', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2014-05-23 until:2015-01-26', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2015-01-26 until:2015-10-02', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2015-10-02 until:2016-06-07', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2016-06-07 until:2017-02-11', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2017-02-11 until:2017-10-17', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2017-10-17 until:2018-06-23', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2018-06-23 until:2019-02-27', 'farmers trump (from:business) until:2019-11-03 since:2017-11-14 since:2019-02-27 until:2019-11-03']\n",
      "INFO: Got 20 tweets (20 new).\n",
      "INFO: Got 40 tweets (20 new).\n",
      "INFO: Got 60 tweets (20 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: queries: ['U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2006-03-21 until:2006-11-24', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2006-11-24 until:2007-07-31', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2007-07-31 until:2008-04-05', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2008-04-05 until:2008-12-10', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2008-12-10 until:2009-08-15', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2009-08-15 until:2010-04-21', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2010-04-21 until:2010-12-26', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2010-12-26 until:2011-09-01', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2011-09-01 until:2012-05-06', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2012-05-06 until:2013-01-10', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2013-01-10 until:2013-09-16', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2013-09-16 until:2014-05-23', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2014-05-23 until:2015-01-26', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2015-01-26 until:2015-10-02', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2015-10-02 until:2016-06-07', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2016-06-07 until:2017-02-11', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2017-02-11 until:2017-10-17', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2017-10-17 until:2018-06-23', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2018-06-23 until:2019-02-27', 'U.S. farmers (from:business) until:2019-03-11 since:2017-11-14 since:2019-02-27 until:2019-11-03']\n",
      "INFO: Got 20 tweets (20 new).\n",
      "INFO: Got 30 tweets (10 new).\n",
      "INFO: Got 32 tweets (2 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n",
      "INFO: Got 32 tweets (0 new).\n"
     ]
    }
   ],
   "source": [
    "from twitterscraper import query_tweets\n",
    "\n",
    "tweet_soy = []\n",
    "for tweet in query_tweets(\"soybeans (from:business) until:2019-11-03 since:2017-11-14\", 20):\n",
    "    tweet_soy.append([str(tweet.timestamp.date()), str(tweet.text.encode('utf-8'))])\n",
    "\n",
    "tweet_farmTrump = []\n",
    "for tweet in query_tweets(\"farmers trump (from:business) until:2019-11-03 since:2017-11-14\", 20):\n",
    "    tweet_farmTrump.append([str(tweet.timestamp.date()), str(tweet.text.encode('utf-8'))])\n",
    "\n",
    "tweet_farmers = []\n",
    "for tweet in query_tweets(\"U.S. farmers (from:business) until:2019-03-11 since:2017-11-14\", 20):\n",
    "    tweet_farmers.append([str(tweet.timestamp.date()), str(tweet.text.encode('utf-8'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_array = tweet_soy + tweet_farmers + tweet_farmTrump\n",
    "len(tweet_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date                                              Tweet\n",
      "0    2019-10-23  Chinese buyers are back in the market for Amer...\n",
      "1    2019-10-22  U.S. farmers are competing for with cheaper Br...\n",
      "2    2019-10-15  American soybean shipments to China already we...\n",
      "3    2019-10-08  Corn and soybean growers in the U.S. aren\\xe2\\...\n",
      "4    2019-10-04  The Trump administration pledges to boost dema...\n",
      "..          ...                                                ...\n",
      "147  2019-08-15  Trump managed to insult Americas wheat farmers...\n",
      "148  2019-08-14  Trump managed to insult Americas wheat farmers...\n",
      "149  2019-08-14  Trump managed to insult Americas wheat farmers...\n",
      "150  2019-08-13  American farmers already hit by Trump\\xe2\\x80\\...\n",
      "151  2019-08-08  U.S. farmers discontent bubbles over in confro...\n",
      "\n",
      "[152 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tweet_df = pd.DataFrame(tweet_array, columns=['Date', 'Tweet'])\n",
    "\n",
    "tweet_df['Tweet'] = tweet_df['Tweet'].str.replace(\"b'\", \"\")\n",
    "tweet_df['Tweet'] = tweet_df['Tweet'].str.replace('b\"', '')\n",
    "tweet_df['Tweet'] = tweet_df['Tweet'].str.replace(\"'\", \"\")\n",
    "\n",
    "# tweet_df = tweet_df.drop_duplicates()\n",
    "print(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.to_csv('Bloomberg_tweet.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet1</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>Chinese buyers are back in the market for Amer...</td>\n",
       "      <td>Chinese buyers are back in the market for Amer...</td>\n",
       "      <td>bloom.bg/2BxS0iP\\xc2\\xa0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>U.S. farmers are competing for with cheaper Br...</td>\n",
       "      <td>U.S. farmers are competing for with cheaper Br...</td>\n",
       "      <td>bloom.bg/33Z3uIF\\xc2\\xa0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>American soybean shipments to China already we...</td>\n",
       "      <td>American soybean shipments to China already we...</td>\n",
       "      <td>bloom.bg/2MK2IYY\\xc2\\xa0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>Corn and soybean growers in the U.S. aren\\xe2\\...</td>\n",
       "      <td>Corn and soybean growers in the U.S. aren\\xe2\\...</td>\n",
       "      <td>bloom.bg/2OwQhSW\\xc2\\xa0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>The Trump administration pledges to boost dema...</td>\n",
       "      <td>The Trump administration pledges to boost dema...</td>\n",
       "      <td>bloom.bg/2LIO84u\\xc2\\xa0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Tweet  \\\n",
       "0  2019-10-23  Chinese buyers are back in the market for Amer...   \n",
       "1  2019-10-22  U.S. farmers are competing for with cheaper Br...   \n",
       "2  2019-10-15  American soybean shipments to China already we...   \n",
       "3  2019-10-08  Corn and soybean growers in the U.S. aren\\xe2\\...   \n",
       "4  2019-10-04  The Trump administration pledges to boost dema...   \n",
       "\n",
       "                                              Tweet1                      Link  \n",
       "0  Chinese buyers are back in the market for Amer...  bloom.bg/2BxS0iP\\xc2\\xa0  \n",
       "1  U.S. farmers are competing for with cheaper Br...  bloom.bg/33Z3uIF\\xc2\\xa0  \n",
       "2  American soybean shipments to China already we...  bloom.bg/2MK2IYY\\xc2\\xa0  \n",
       "3  Corn and soybean growers in the U.S. aren\\xe2\\...  bloom.bg/2OwQhSW\\xc2\\xa0  \n",
       "4  The Trump administration pledges to boost dema...  bloom.bg/2LIO84u\\xc2\\xa0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df1 = pd.read_csv('Bloomberg_tweet.csv', sep = '|', )[['Date', 'Tweet']]\n",
    "tweet_df1[['Tweet1', 'Link']] = tweet_df1['Tweet'].str.split('https://',expand=True)\n",
    "tweet_df1 = tweet_df1.drop_duplicates()\n",
    "tweet_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def neg(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['neg']\n",
    "\n",
    "def neu(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['neu']\n",
    "\n",
    "def pos(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['pos']\n",
    "\n",
    "def comp(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['compound']\n",
    "\n",
    "# tweet_df1 = pd.read_csv('tweet.csv', sep = '|')\n",
    "\n",
    "tweet_df1['neg'] = tweet_df1['Tweet1'].apply(neg)\n",
    "tweet_df1['neu'] = tweet_df1['Tweet1'].apply(neu)\n",
    "tweet_df1['pos'] = tweet_df1['Tweet1'].apply(pos)\n",
    "\n",
    "tweet_df1 = tweet_df1.sort_values('Date')\n",
    "tweet_df1[['Date', 'neg', 'pos', 'neu']].to_csv('Tweet_Trump.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2006-03-21 until:2006-11-24', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2006-11-24 until:2007-07-31', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2007-07-31 until:2008-04-05', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2008-04-05 until:2008-12-10', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2008-12-10 until:2009-08-15', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2009-08-15 until:2010-04-21', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2010-04-21 until:2010-12-26', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2010-12-26 until:2011-09-01', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2011-09-01 until:2012-05-06', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2012-05-06 until:2013-01-10', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2013-01-10 until:2013-09-16', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2013-09-16 until:2014-05-23', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2014-05-23 until:2015-01-26', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2015-01-26 until:2015-10-02', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2015-10-02 until:2016-06-07', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2016-06-07 until:2017-02-11', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2017-02-11 until:2017-10-17', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2017-10-17 until:2018-06-23', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2018-06-23 until:2019-02-27', '(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14 since:2019-02-27 until:2019-11-03']\n",
      "INFO: Got 20 tweets (20 new).\n",
      "INFO: Got 40 tweets (20 new).\n",
      "INFO: Got 60 tweets (20 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n"
     ]
    }
   ],
   "source": [
    "tweet_asa = []\n",
    "for tweet in query_tweets(\"(from:ASA_Soybeans) until:2019-11-03 since:2017-11-14\", 20):\n",
    "    tweet_asa.append([str(tweet.timestamp.date()), str(tweet.text.encode('utf-8'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2018-06-22',\n",
       "  \"b'In this episode of http://ILSoyAdvisor.com\\\\xc2\\\\xa0    Profitability Radio, Todd Doehring, director @ Centrec Consulting/V.P. of FFSC, talks efforts to helping farmers use financial terms, statements to help with management decision making. @ILSoybean @ILSoyAdvisor http://ow.ly/JxUg30k0TJR\\\\xc2\\\\xa0pic.twitter.com/e2k8ARuAkt'\"],\n",
       " ['2018-06-22',\n",
       "  \"b'Soy Growers Urge Senate Support for Export Programs http://ow.ly/12S930kCqZl\\\\xc2\\\\xa0 #soyleaders #Exports #farmbillpic.twitter.com/OrlFdzImQn'\"],\n",
       " ['2018-06-22',\n",
       "  \"b'ASA continues to ask the Administration to work with #soybean #farmers to find ways to reduce our trade deficit by increasing competitiveness rather than erecting barriers to foreign markets. Read more: http://ow.ly/LynS30kCqHP\\\\xc2\\\\xa0 #RethinkTheTariffs #TradeNotTariffspic.twitter.com/b08uYMyjep'\"],\n",
       " ['2018-06-22',\n",
       "  'b\"If you\\'re a farming individual/couple and passionate about the future possibilities of #agriculture--we\\'re looking for you! ASA & @cortevaare now accepting applicants for the Young Leader program: http://ow.ly/gNZj30kBCMn\\\\xc2\\\\xa0 #soyleaderspic.twitter.com/HGJaxvHkul\"'],\n",
       " ['2018-06-21',\n",
       "  \"b'#Soybean growers applaud the successful effort to reconsider the House  #FarmBill. http://ow.ly/5qlb30kBOn2\\\\xc2\\\\xa0pic.twitter.com/D1xF4BjLQ9'\"]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_asa[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_asa = pd.DataFrame(tweet_asa, columns=['Date', 'Tweet'])\n",
    "\n",
    "tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace(\"b'\", \"\")\n",
    "tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace('b\"', '')\n",
    "tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace(\"'\", \"\")\n",
    "# tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace(\"\\xe2\\x80\\x99\", \"'\")\n",
    "# tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace(\"\\\\xe2\", \"\")\n",
    "# tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace(\"\\\\x80\", \"\")\n",
    "# tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace(\"\\\\x93\", \"\")\n",
    "# tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace(\"\\\\x99\", \"\")\n",
    "# tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace(\"\\\\xc2\", \"\")\n",
    "# tweet_asa['Tweet'] = tweet_asa['Tweet'].str.replace(\"\\\\xa0\", \"\")\n",
    "\n",
    "tweet_asa = tweet_asa.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_asa.to_csv('tweet_asa_text.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>In this episode of http://ILSoyAdvisor.com    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>Soy Growers Urge Senate Support for Export Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>ASA continues to ask the Administration to wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>If youre a farming individual/couple and passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>#Soybean growers applaud the successful effort...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Tweet\n",
       "0  2018-06-22  In this episode of http://ILSoyAdvisor.com    ...\n",
       "1  2018-06-22  Soy Growers Urge Senate Support for Export Pro...\n",
       "2  2018-06-22  ASA continues to ask the Administration to wor...\n",
       "3  2018-06-22  If youre a farming individual/couple and passi...\n",
       "4  2018-06-21  #Soybean growers applaud the successful effort..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df1 = pd.read_csv('tweet_asa_text.csv', sep = '|', )[['Date', 'Tweet']]\n",
    "tweet_df1 = tweet_df1.drop_duplicates()\n",
    "tweet_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def neg(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['neg']\n",
    "\n",
    "def neu(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['neu']\n",
    "\n",
    "def pos(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['pos']\n",
    "\n",
    "def comp(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['compound']\n",
    "\n",
    "# tweet_df1 = pd.read_csv('tweet_asa.csv', sep = '|')\n",
    "\n",
    "tweet_df1['neg'] = tweet_df1['Tweet'].apply(neg)\n",
    "tweet_df1['neu'] = tweet_df1['Tweet'].apply(neu)\n",
    "tweet_df1['pos'] = tweet_df1['Tweet'].apply(pos)\n",
    "\n",
    "tweet_df1 = tweet_df1.sort_values('Date')\n",
    "tweet_df1[['Date', 'neg', 'pos', 'neu']].to_csv('tweet_asa.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>1 in 3 rows of soybeans are exported to China....</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>Did you know that soy is the top agricultural ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>ASA, on behalf of all U.S. #soy growers, is di...</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>ASA urges the Administration to rescind the ta...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>China announced it will impose a 25 percent ta...</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                              Tweet    neg  \\\n",
       "19  2018-06-14  1 in 3 rows of soybeans are exported to China....  0.000   \n",
       "18  2018-06-15  Did you know that soy is the top agricultural ...  0.000   \n",
       "17  2018-06-15  ASA, on behalf of all U.S. #soy growers, is di...  0.077   \n",
       "16  2018-06-15  ASA urges the Administration to rescind the ta...  0.000   \n",
       "15  2018-06-15  China announced it will impose a 25 percent ta...  0.059   \n",
       "\n",
       "      neu    pos  \n",
       "19  0.860  0.140  \n",
       "18  0.753  0.247  \n",
       "17  0.798  0.125  \n",
       "16  0.944  0.056  \n",
       "15  0.892  0.049  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farm Futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2006-03-21 until:2006-11-24', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2006-11-24 until:2007-07-31', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2007-07-31 until:2008-04-05', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2008-04-05 until:2008-12-10', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2008-12-10 until:2009-08-15', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2009-08-15 until:2010-04-21', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2010-04-21 until:2010-12-26', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2010-12-26 until:2011-09-01', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2011-09-01 until:2012-05-06', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2012-05-06 until:2013-01-10', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2013-01-10 until:2013-09-16', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2013-09-16 until:2014-05-23', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2014-05-23 until:2015-01-26', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2015-01-26 until:2015-10-02', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2015-10-02 until:2016-06-07', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2016-06-07 until:2017-02-11', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2017-02-11 until:2017-10-17', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2017-10-17 until:2018-06-23', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2018-06-23 until:2019-02-27', 'soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14 since:2019-02-27 until:2019-11-03']\n",
      "INFO: Got 20 tweets (20 new).\n",
      "INFO: Got 40 tweets (20 new).\n",
      "INFO: Got 60 tweets (20 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n",
      "INFO: Got 60 tweets (0 new).\n"
     ]
    }
   ],
   "source": [
    "tweet_FF = []\n",
    "for tweet in query_tweets(\"soybean (from:FarmFutures) until:2019-11-03 since:2017-11-14\", 20):\n",
    "    tweet_FF.append([str(tweet.timestamp.date()), str(tweet.text.encode('utf-8'))])\n",
    "    \n",
    "tweet_FF = pd.DataFrame(tweet_FF, columns=['Date', 'Tweet'])\n",
    "tweet_FF['Tweet'] = tweet_FF['Tweet'].str.replace(\"b'\", \"\")\n",
    "tweet_FF['Tweet'] = tweet_FF['Tweet'].str.replace('b\"', '')\n",
    "tweet_FF['Tweet'] = tweet_FF['Tweet'].str.replace(\"'\", \"\")\n",
    "\n",
    "tweet_FF.to_csv('tweet_FF_text.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Weekly Export Sales  In search of momentum Soy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>Weekly Export Sales  In search of momentum Soy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>Weekly Export Sales  In search of momentum Soy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>Weekly Export Sales  In search of momentum Soy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>Weekly Export Sales  In search of momentum Soy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Tweet\n",
       "0  2019-11-01  Weekly Export Sales  In search of momentum Soy...\n",
       "1  2019-10-31  Weekly Export Sales  In search of momentum Soy...\n",
       "2  2019-10-31  Weekly Export Sales  In search of momentum Soy...\n",
       "3  2019-10-31  Weekly Export Sales  In search of momentum Soy...\n",
       "4  2019-10-31  Weekly Export Sales  In search of momentum Soy..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df1 = pd.read_csv('tweet_FF_text.csv', sep = '|', )[['Date', 'Tweet']]\n",
    "tweet_df1 = tweet_df1.drop_duplicates()\n",
    "tweet_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def neg(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['neg']\n",
    "\n",
    "def neu(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['neu']\n",
    "\n",
    "def pos(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['pos']\n",
    "\n",
    "def comp(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['compound']\n",
    "\n",
    "# tweet_df1 = pd.read_csv('tweet_asa.csv', sep = '|')\n",
    "\n",
    "tweet_df1['neg'] = tweet_df1['Tweet'].apply(neg)\n",
    "tweet_df1['neu'] = tweet_df1['Tweet'].apply(neu)\n",
    "tweet_df1['pos'] = tweet_df1['Tweet'].apply(pos)\n",
    "\n",
    "tweet_df1 = tweet_df1.sort_values('Date')\n",
    "tweet_df1[['Date', 'neg', 'pos', 'neu']].to_csv('tweet_FF.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2006-03-21 until:2006-11-24', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2006-11-24 until:2007-07-31', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2007-07-31 until:2008-04-05', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2008-04-05 until:2008-12-10', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2008-12-10 until:2009-08-15', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2009-08-15 until:2010-04-21', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2010-04-21 until:2010-12-26', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2010-12-26 until:2011-09-01', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2011-09-01 until:2012-05-06', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2012-05-06 until:2013-01-10', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2013-01-10 until:2013-09-16', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2013-09-16 until:2014-05-23', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2014-05-23 until:2015-01-26', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2015-01-26 until:2015-10-02', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2015-10-02 until:2016-06-07', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2016-06-07 until:2017-02-11', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2017-02-11 until:2017-10-17', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2017-10-17 until:2018-06-23', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2018-06-23 until:2019-02-27', 'soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14 since:2019-02-27 until:2019-11-03']\n",
      "INFO: Got 6 tweets (6 new).\n",
      "INFO: Got 26 tweets (20 new).\n",
      "INFO: Got 46 tweets (20 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n",
      "INFO: Got 46 tweets (0 new).\n"
     ]
    }
   ],
   "source": [
    "tweet_agweb = []\n",
    "for tweet in query_tweets(\"soybeans (from:AgWebEditor) until:2019-11-03 since:2017-11-14\", 20):\n",
    "    tweet_agweb.append([str(tweet.timestamp.date()), str(tweet.text.encode('utf-8'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_agweb = pd.DataFrame(tweet_agweb, columns=['Date', 'Tweet'])\n",
    "\n",
    "tweet_agweb['Tweet'] = tweet_agweb['Tweet'].str.replace(\"b'\", \"\")\n",
    "tweet_agweb['Tweet'] = tweet_agweb['Tweet'].str.replace('b\"', '')\n",
    "tweet_agweb['Tweet'] = tweet_agweb['Tweet'].str.replace(\"'\", \"\")\n",
    "\n",
    "tweet_agweb.to_csv('tweet_agweb_text.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>In this episode of http://ILSoyAdvisor.com    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>Soy Growers Urge Senate Support for Export Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>ASA continues to ask the Administration to wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>If youre a farming individual/couple and passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>#Soybean growers applaud the successful effort...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Tweet\n",
       "0  2018-06-22  In this episode of http://ILSoyAdvisor.com    ...\n",
       "1  2018-06-22  Soy Growers Urge Senate Support for Export Pro...\n",
       "2  2018-06-22  ASA continues to ask the Administration to wor...\n",
       "3  2018-06-22  If youre a farming individual/couple and passi...\n",
       "4  2018-06-21  #Soybean growers applaud the successful effort..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df1 = pd.read_csv('tweet_asa_text.csv', sep = '|', )[['Date', 'Tweet']]\n",
    "tweet_df1 = tweet_df1.drop_duplicates()\n",
    "tweet_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def neg(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['neg']\n",
    "\n",
    "def neu(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['neu']\n",
    "\n",
    "def pos(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['pos']\n",
    "\n",
    "def comp(x):\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['compound']\n",
    "\n",
    "tweet_df1['neg'] = tweet_df1['Tweet'].apply(neg)\n",
    "tweet_df1['neu'] = tweet_df1['Tweet'].apply(neu)\n",
    "tweet_df1['pos'] = tweet_df1['Tweet'].apply(pos)\n",
    "\n",
    "tweet_df1 = tweet_df1.sort_values('Date')\n",
    "tweet_df1[['Date', 'neg', 'pos', 'neu']].to_csv('tweet_agweb.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
